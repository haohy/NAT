{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import de_core_news_sm\n",
    "spacy_en = en_core_web_sm.load()\n",
    "spacy_de = de_core_news_sm.load()\n",
    "\n",
    "from IPython import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderStack(nn.Module):\n",
    "    \"\"\"The encoder stack of NAT.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_embed=512, nhead=8, num_encoder_layers=6, dim_feedforward=2048, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderStack, self).__init__()\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_embed, nhead, dim_feedforward, dropout)\n",
    "        encoder_norm = nn.LayerNorm(d_embed)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_encoder_layers, encoder_norm)\n",
    "        \n",
    "    def forward(self, src, mask=None, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        Shape:\n",
    "            src: [S, N, E]\n",
    "            output: [S, N, E]\n",
    "        \"\"\"\n",
    "        output = self.encoder(src, mask, src_key_padding_mask)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional Encoding.\n",
    "    \n",
    "    Args:\n",
    "        d_embed: int, the dimension of embedding.\n",
    "        max_seq_len: int, the max length of what to be summed with positional encoding.\n",
    "    \n",
    "    \"\"\"\n",
    "    def  __init__(self, d_embed, max_seq_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        self.d_embed = d_embed\n",
    "        pe = torch.zeros(max_seq_len, d_embed) # pe: [T, E]\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_embed, 2):\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(pos / (10000 ** ((2 * i)/d_embed)))\n",
    "                pe[pos, i + 1] = \\\n",
    "                math.cos(pos / (10000 ** ((2 * (i + 1))/d_embed)))\n",
    "                \n",
    "        pe = pe.unsqueeze(0) # pe: [1, T, E]\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make embeddings relatively larger\n",
    "        x = x * math.sqrt(self.d_embed) # x: [T, N, E]\n",
    "        #add constant to embedding\n",
    "        seq_len = x.size(0)\n",
    "        \n",
    "        pe = self.pe[:, :seq_len].repeat(x.size(1),1,1).transpose(0,1) # pe: [T, N, E]\n",
    "        pe = Variable(pe, requires_grad=False)\n",
    "        x = x.cuda() if pe.is_cuda else x\n",
    "        x = x + pe\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadPositionalAttention(nn.Module):\n",
    "    \"\"\"Multi-Head Positional Attention sublayer.\"\"\"\n",
    "    def __init__(self, d_embed, num_heads, max_seq_len=100, dropout=0., bias=True, add_bias_kv=False,\n",
    "                 add_zero_attn=False, kdim=None, vdim=None):\n",
    "        super(MultiHeadPositionalAttention, self).__init__()\n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(d_embed, max_seq_len)\n",
    "    \n",
    "        self.multi_head_attn = nn.MultiheadAttention(d_embed, num_heads, dropout, bias, \n",
    "                                                     add_bias_kv, add_zero_attn, kdim, vdim)\n",
    "        \n",
    "    def forward(self, query, key, value, key_padding_mask=None, need_weights=True, \n",
    "                attn_mask=None):\n",
    "        query = self.positional_encoding(query) # query: [L, N, E]\n",
    "        key = self.positional_encoding(key) # key: [S, N, E]\n",
    "        value = self.positional_encoding(value) # value: [S, N, E], L = S\n",
    "        \n",
    "        # attn_output: [L, N, E], attn_output_weights: [N, L, S]\n",
    "        attn_output, _ = self.multi_head_attn(query, key, value, key_padding_mask, \n",
    "                                                                need_weights, attn_mask)\n",
    "        \n",
    "        return attn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"The sublayer of DecoderStack.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_embed, nhead, max_seq_len=100, dim_feedforward=2048, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.multi_head_self_attn = nn.MultiheadAttention(d_embed, nhead, dropout)\n",
    "        self.multi_head_pos_attn = MultiHeadPositionalAttention(d_embed, nhead, max_seq_len, dropout)\n",
    "        self.multi_head_inter_attn = nn.MultiheadAttention(d_embed, nhead, dropout)\n",
    "        \n",
    "        # Implementation of Feedforward model\n",
    "        self.linear1 = nn.Linear(d_embed, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_embed)\n",
    "\n",
    "        # Implementation of MultiHead-Attentions\n",
    "        self.norm1 = nn.LayerNorm(d_embed)\n",
    "        self.norm2 = nn.LayerNorm(d_embed)\n",
    "        self.norm3 = nn.LayerNorm(d_embed)\n",
    "        self.norm4 = nn.LayerNorm(d_embed)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.dropout4 = nn.Dropout(dropout)\n",
    "\n",
    "        self.d_embed = d_embed\n",
    "        \n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,\n",
    "                tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        \"\"\"DecoderLayer is made up of self-attn, multi-head-attn and feedforward network.\n",
    "        \n",
    "        Shape:\n",
    "            tgt: [T, N, E].\n",
    "            memory: [S, N, E]\n",
    "        \"\"\"\n",
    "        tgt_len, bsz = tgt.size(0), tgt.size(1)\n",
    "        \n",
    "        # define tgt_mask\n",
    "        if tgt_mask is None:\n",
    "            diag_ones = np.array([1]*tgt_len)\n",
    "            tgt_mask = torch.from_numpy(np.diag(diag_ones)).bool()\n",
    "            tgt_mask = tgt_mask.float().masked_fill(tgt_mask, float('-inf'))\n",
    "        \n",
    "        # multi-head self-attention\n",
    "        tgt2 = self.multi_head_self_attn(tgt, tgt, tgt)[0]\n",
    "        tgt = tgt + self.dropout1(tgt2)\n",
    "        tgt = self.norm1(tgt)\n",
    "        \n",
    "        # multi-head positional attention\n",
    "        tgt2 = self.multi_head_pos_attn(tgt, tgt, tgt)[0]\n",
    "        tgt = tgt + self.dropout2(tgt2)\n",
    "        tgt = self.norm2(tgt)\n",
    "        \n",
    "        # multi-head inter-attention\n",
    "        tgt2 = self.multi_head_inter_attn(tgt, memory, memory)[0]\n",
    "        tgt = tgt + self.dropout3(tgt2)\n",
    "        tgt = self.norm3(tgt)\n",
    "        \n",
    "        # position-wise feed forward layer\n",
    "        tgt2 = self.linear2(self.dropout(F.relu(self.linear1(tgt))))\n",
    "        tgt = tgt + self.dropout4(tgt2)\n",
    "        tgt = self.norm4(tgt)\n",
    "        \n",
    "        return tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderStack(nn.Module):\n",
    "    \"\"\"The decoder stack of NAT.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_embed=512, nhead=8, max_seq_len=1000, num_decoder_layers=6, \n",
    "                 dim_feedforward=2048, dropout=0.1, activation=\"relu\"):\n",
    "        super(DecoderStack, self).__init__()\n",
    "        \n",
    "        decoder_layer = DecoderLayer(d_embed, nhead, max_seq_len, dim_feedforward, dropout)\n",
    "        decoder_norm = nn.LayerNorm(d_embed)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_decoder_layers, decoder_norm)\n",
    "        \n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        Shape:\n",
    "            tgt: [T, N, E]\n",
    "            memory: [S, N, E]\n",
    "            output: [T, N, E]\n",
    "        \"\"\"\n",
    "        output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n",
    "                              tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                              memory_key_padding_mask=memory_key_padding_mask)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FertilityPredictor(nn.Module):\n",
    "    \"\"\"The fertility predictor of NAT.\n",
    "    \n",
    "    Args:\n",
    "        d_embed: the dimension of EncoderStack's output.\n",
    "        L: the number of the classes used to represent fertility.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_embed, L):\n",
    "        super(FertilityPredictor, self).__init__()\n",
    "        \n",
    "        self.fc_layer = nn.Linear(d_embed, L)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, encoder_output):\n",
    "        \"\"\"Using EncoderStack's output to predict fertility list.\n",
    "        \n",
    "        Shape:\n",
    "            encoder_output: [S, N, E]\n",
    "            fertility_list: [S, N]\n",
    "        \"\"\"\n",
    "        fertility_list = F.softmax(self.relu(self.fc_layer(encoder_output)), dim=-1) # fertility_list: [S, N, L]\n",
    "        fertility_list = torch.argmax(fertility_list, dim=-1) # fertility_list: [S, N]\n",
    "        \n",
    "        return fertility_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationPredictor(nn.Module):\n",
    "    \"\"\"The translation predictor of NAT.\n",
    "\n",
    "    Args:\n",
    "        d_embed: the dimension of EncoderStack's output.\n",
    "        vocab: the number of the classes used to represent fertility.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_embed, vocab):\n",
    "        super(TranslationPredictor, self).__init__()\n",
    "        \n",
    "        self.fc_layer = nn.Linear(d_embed, vocab)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, decoder_output):\n",
    "        \"\"\"Using DecoderStack's output to predict translation.\n",
    "        \n",
    "        Shape:\n",
    "            decoder_output: [S, N, E]\n",
    "            translation_output: [S, N, vocab]\n",
    "        \"\"\"\n",
    "        translation_output = F.softmax(self.relu(self.fc_layer(decoder_output)), dim=-1)\n",
    "        \n",
    "        return translation_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NAT(nn.Module):\n",
    "    \"\"\"Non-Autoregressive Transformer.\n",
    "    \n",
    "    Args:\n",
    "        vocab_src: int, the size of source vocabulary.\n",
    "        vocab_tgt: int, the size of target vocabulary.\n",
    "        d_embed: int, the dimension of embedded input.\n",
    "        S: int, the length of source input sentence.\n",
    "        L: int, the number of the classes used to represent fertility.\n",
    "        \n",
    "    Shape:\n",
    "        input: LongTensor, [N, S]\n",
    "        output: FloatTensor, [T, N, vocab_tgt], T=S*L    \n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_src, vocab_tgt, S, d_embed=512, L=50, nhead=8, num_encoder_layers=6,\n",
    "                 num_decoder_layers=6, dim_feedforward=2048, dropout=0.1, activation=\"relu\"):\n",
    "        super(NAT, self).__init__()\n",
    "        \n",
    "        self.d_embed = d_embed\n",
    "        self.S = S\n",
    "        self.L = L\n",
    "        self.T = S*L\n",
    "        max_seq_len = S*L\n",
    "        \n",
    "        self.embedding_input = nn.Embedding(vocab_src, d_embed)\n",
    "        self.position_encoder_en = PositionalEncoding(d_embed, S)\n",
    "        self.position_encoder_de = PositionalEncoding(d_embed, S*L)\n",
    "        self.encoder = EncoderStack(d_embed, nhead, num_encoder_layers, dim_feedforward, dropout, activation)\n",
    "        self.fertility_predictor = FertilityPredictor(d_embed, L)\n",
    "        self.decoder = DecoderStack(d_embed, nhead, max_seq_len, num_decoder_layers, dim_feedforward, dropout, activation)\n",
    "        self.translation_predictor = TranslationPredictor(d_embed, vocab_tgt)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        input_e = self.embedding_input(input.transpose(0,1)) # input_e: [S, N, E]\n",
    "        input_pe = self.position_encoder_en(input_e) # input_pe: [S, N, E]\n",
    "        encoder_output = self.encoder(input_e) # encoder_output: [S, N, E] ---------------\n",
    "        fertility_list = self.fertility_predictor(encoder_output) # fertility_list: [S, N]\n",
    "        copied_embedding = self.copy_fertility(input_e, fertility_list, self.L) # copied_embedding: [T, N, E]\n",
    "        copied_embedding_pe = self.position_encoder_de(copied_embedding) # copied_embedding_pe: [T, N, E]\n",
    "        memory = encoder_output\n",
    "        decoder_output = self.decoder(copied_embedding_pe, memory) # decoder_output: [T, N, E]\n",
    "        output = self.translation_predictor(decoder_output) # output: [T, N, E]\n",
    "        \n",
    "        return output\n",
    "        \n",
    "        \n",
    "    def copy_fertility(self, input_e, fertility_list, L):\n",
    "        \"\"\"Copy the input embedding as the number at corresponding index.\n",
    "        \n",
    "        Args:\n",
    "            input_e: [S, N, E].\n",
    "            fertility_list: [S, N].\n",
    "            L: int, the number of the classes used to represent fertility.\n",
    "        \n",
    "        Output:\n",
    "            copied_embedding: [T, N, E]\n",
    "        \"\"\"\n",
    "        # copy as fertitlity list\n",
    "        [S, N, E] = input_e.shape\n",
    "        copied_embedding = torch.zeros(N, S*L, E) # copied_embedding: [N, S*L, E]\n",
    "        input_e_permute = input_e.permute(1,0,2) # input_e_permute: [N, S, E]\n",
    "        fertility_list_permute = fertility_list.transpose(0,1) # fertility_list_permuet: [N, S]\n",
    "        \n",
    "        # use fertility list and embedded input to get decoder's input.\n",
    "        for i, fertility_batch in enumerate(fertility_list_permute):\n",
    "            pos = 0\n",
    "            for j, fertility_j in enumerate(fertility_batch):\n",
    "                if fertility_j == 0:\n",
    "                    continue\n",
    "                copied_embedding[i,pos:pos+int(fertility_j),:] = input_e_permute[i,j,:].repeat(1,int(fertility_j),1)\n",
    "                pos += int(fertility_j)\n",
    "        copied_embedding = copied_embedding.transpose(0,1)\n",
    "        \n",
    "        return copied_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randint(0, 1000, (16, 20)).long().cuda() # input: [N, S]\n",
    "model = NAT(vocab_src=1000, vocab_tgt=500, S=20).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 490.00 MiB (GPU 0; 11.91 GiB total capacity; 1.21 GiB already allocated; 31.25 MiB free; 24.85 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-81457ca7acca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-291384291d89>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mcopied_embedding_pe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_encoder_de\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopied_embedding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# copied_embedding_pe: [T, N, E]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopied_embedding_pe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# decoder_output: [T, N, E]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslation_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# output: [T, N, E]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-0579be188e54>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m     20\u001b[0m         output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n\u001b[1;32m     21\u001b[0m                               \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                               memory_key_padding_mask=memory_key_padding_mask)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.5/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    214\u001b[0m                                     \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                                     \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                                     memory_key_padding_mask=memory_key_padding_mask)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-66849cb0fb2a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# multi-head self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mtgt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_head_self_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.5/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m                 \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 attn_mask=attn_mask)\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dnn/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   3245\u001b[0m                                                device=key_padding_mask.device)], dim=1)\n\u001b[1;32m   3246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3247\u001b[0;31m     \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3248\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 490.00 MiB (GPU 0; 11.91 GiB total capacity; 1.21 GiB already allocated; 31.25 MiB free; 24.85 MiB cached)"
     ]
    }
   ],
   "source": [
    "output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 16, 500])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
