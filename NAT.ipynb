{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import de_core_news_sm\n",
    "spacy_en = en_core_web_sm.load()\n",
    "spacy_de = de_core_news_sm.load()\n",
    "\n",
    "from IPython import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderStack(nn.Module):\n",
    "    \"\"\"The encoder stack of NAT.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_embed=512, nhead=8, num_encoder_layers=6, dim_feedforward=2048, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderStack, self).__init__()\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_embed, nhead, dim_feedforward, dropout)\n",
    "        encoder_norm = nn.LayerNorm(d_embed)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_encoder_layers, encoder_norm)\n",
    "        \n",
    "    def forward(self, src, mask=None, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        Shape:\n",
    "            src: [S, N, E]\n",
    "            output: [S, N, E]\n",
    "        \"\"\"\n",
    "        output = self.encoder(src, mask, src_key_padding_mask)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional Encoding.\n",
    "    \n",
    "    Args:\n",
    "        d_embed: int, the dimension of embedding.\n",
    "        max_seq_len: int, the max length of what to be summed with positional encoding.\n",
    "    \n",
    "    \"\"\"\n",
    "    def  __init__(self, d_embed, max_seq_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        self.d_embed = d_embed\n",
    "        pe = torch.zeros(max_seq_len, d_embed) # pe: [T, E]\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_embed, 2):\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(pos / (10000 ** ((2 * i)/d_embed)))\n",
    "                pe[pos, i + 1] = \\\n",
    "                math.cos(pos / (10000 ** ((2 * (i + 1))/d_embed)))\n",
    "                \n",
    "        pe = pe.unsqueeze(0) # pe: [1, T, E]\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make embeddings relatively larger\n",
    "        x = x * math.sqrt(self.d_embed) # x: [T, N, E]\n",
    "        #add constant to embedding\n",
    "        seq_len = x.size(0)\n",
    "        \n",
    "        pe = self.pe[:, :seq_len].repeat(x.size(1),1,1).transpose(0,1) # pe: [T, N, E]\n",
    "        pe = Variable(pe, requires_grad=False)\n",
    "        x = x + pe\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadPositionalAttention(nn.Module):\n",
    "    \"\"\"Multi-Head Positional Attention sublayer.\"\"\"\n",
    "    def __init__(self, d_embed, num_heads, max_seq_len=100, dropout=0., bias=True, add_bias_kv=False,\n",
    "                 add_zero_attn=False, kdim=None, vdim=None):\n",
    "        super(MultiHeadPositionalAttention, self).__init__()\n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(d_embed, max_seq_len)\n",
    "    \n",
    "        self.multi_head_attn = nn.MultiheadAttention(d_embed, num_heads, dropout, bias, \n",
    "                                                     add_bias_kv, add_zero_attn, kdim, vdim)\n",
    "        \n",
    "    def forward(self, query, key, value, key_padding_mask=None, need_weights=True, \n",
    "                attn_mask=None):\n",
    "        query = self.positional_encoding(query) # query: [L, N, E]\n",
    "        key = self.positional_encoding(key) # key: [S, N, E]\n",
    "        value = self.positional_encoding(value) # value: [S, N, E], L = S\n",
    "        \n",
    "        # attn_output: [L, N, E], attn_output_weights: [N, L, S]\n",
    "        attn_output, _ = self.multi_head_attn(query, key, value, key_padding_mask, \n",
    "                                                                need_weights, attn_mask)\n",
    "        \n",
    "        return attn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"The sublayer of DecoderStack.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_embed, nhead, max_seq_len=100, dim_feedforward=2048, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.multi_head_self_attn = nn.MultiheadAttention(d_embed, nhead, dropout)\n",
    "        self.multi_head_pos_attn = MultiHeadPositionalAttention(d_embed, nhead, max_seq_len, dropout)\n",
    "        self.multi_head_inter_attn = nn.MultiheadAttention(d_embed, nhead, dropout)\n",
    "        \n",
    "        # Implementation of Feedforward model\n",
    "        self.linear1 = nn.Linear(d_embed, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_embed)\n",
    "\n",
    "        # Implementation of MultiHead-Attentions\n",
    "        self.norm1 = nn.LayerNorm(d_embed)\n",
    "        self.norm2 = nn.LayerNorm(d_embed)\n",
    "        self.norm3 = nn.LayerNorm(d_embed)\n",
    "        self.norm4 = nn.LayerNorm(d_embed)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.dropout4 = nn.Dropout(dropout)\n",
    "\n",
    "        self.d_embed = d_embed\n",
    "        \n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,\n",
    "                tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        \"\"\"DecoderLayer is made up of self-attn, multi-head-attn and feedforward network.\n",
    "        \n",
    "        Shape:\n",
    "            tgt: [T, N, E].\n",
    "            memory: [S, N, E]\n",
    "        \"\"\"\n",
    "        tgt_len, bsz = tgt.size(0), tgt.size(1)\n",
    "        \n",
    "        # define tgt_mask\n",
    "        if tgt_mask is None:\n",
    "            diag_ones = np.array([1]*tgt_len)\n",
    "            tgt_mask = torch.from_numpy(np.diag(diag_ones)).bool()\n",
    "            tgt_mask = tgt_mask.float().masked_fill(tgt_mask, float('-inf'))\n",
    "        \n",
    "        # multi-head self-attention\n",
    "        tgt2 = self.multi_head_self_attn(tgt, tgt, tgt)[0]\n",
    "        tgt = tgt + self.dropout1(tgt2)\n",
    "        tgt = self.norm1(tgt)\n",
    "        \n",
    "        # multi-head positional attention\n",
    "        tgt2 = self.multi_head_pos_attn(tgt, tgt, tgt)[0]\n",
    "        tgt = tgt + self.dropout2(tgt2)\n",
    "        tgt = self.norm2(tgt)\n",
    "        \n",
    "        # multi-head inter-attention\n",
    "        tgt2 = self.multi_head_inter_attn(tgt, memory, memory)[0]\n",
    "        tgt = tgt + self.dropout3(tgt2)\n",
    "        tgt = self.norm3(tgt)\n",
    "        \n",
    "        # position-wise feed forward layer\n",
    "        tgt2 = self.linear2(self.dropout(F.relu(self.linear1(tgt))))\n",
    "        tgt = tgt + self.dropout4(tgt2)\n",
    "        tgt = self.norm4(tgt)\n",
    "        \n",
    "        return tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderStack(nn.Module):\n",
    "    \"\"\"The decoder stack of NAT.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_embed=512, nhead=8, max_seq_len=1000, num_decoder_layers=6, \n",
    "                 dim_feedforward=2048, dropout=0.1, activation=\"relu\"):\n",
    "        super(DecoderStack, self).__init__()\n",
    "        \n",
    "        decoder_layer = DecoderLayer(d_embed, nhead, max_seq_len, dim_feedforward, dropout)\n",
    "        decoder_norm = nn.LayerNorm(d_embed)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_decoder_layers, decoder_norm)\n",
    "        \n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None,\n",
    "                memory_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        Shape:\n",
    "            tgt: [T, N, E]\n",
    "            memory: [S, N, E]\n",
    "            output: [T, N, E]\n",
    "        \"\"\"\n",
    "        output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n",
    "                              tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                              memory_key_padding_mask=memory_key_padding_mask)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FertilityPredictor(nn.Module):\n",
    "    \"\"\"The fertility predictor of NAT.\n",
    "    \n",
    "    Args:\n",
    "        d_embed: the dimension of EncoderStack's output.\n",
    "        L: the number of the classes used to represent fertility.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_embed, L):\n",
    "        super(FertilityPredictor, self).__init__()\n",
    "        \n",
    "        self.fc_layer = nn.Linear(d_embed, L)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, encoder_output):\n",
    "        \"\"\"Using EncoderStack's output to predict fertility list.\n",
    "        \n",
    "        Shape:\n",
    "            encoder_output: [S, N, E]\n",
    "            fertility_list: [S, N]\n",
    "        \"\"\"\n",
    "        fertility_list = F.softmax(self.relu(self.fc_layer(encoder_output)), dim=-1) # fertility_list: [S, N, L]\n",
    "        fertility_list = torch.argmax(fertility_list, dim=-1) # fertility_list: [S, N]\n",
    "        \n",
    "        return fertility_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationPredictor(nn.Module):\n",
    "    \"\"\"The translation predictor of NAT.\n",
    "\n",
    "    Args:\n",
    "        d_embed: the dimension of EncoderStack's output.\n",
    "        vocab: the number of the classes used to represent fertility.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_embed, vocab):\n",
    "        super(TranslationPredictor, self).__init__()\n",
    "        \n",
    "        self.fc_layer = nn.Linear(d_embed, vocab)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, decoder_output):\n",
    "        \"\"\"Using DecoderStack's output to predict translation.\n",
    "        \n",
    "        Shape:\n",
    "            decoder_output: [S, N, E]\n",
    "            translation_output: [S, N, vocab]\n",
    "        \"\"\"\n",
    "        translation_output = F.softmax(self.relu(self.fc_layer(decoder_output)), dim=-1)\n",
    "        \n",
    "        return translation_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NAT(nn.Module):\n",
    "    \"\"\"Non-Autoregressive Transformer.\n",
    "    \n",
    "    Args:\n",
    "        vocab_src: int, the size of source vocabulary.\n",
    "        vocab_tgt: int, the size of target vocabulary.\n",
    "        d_embed: int, the dimension of embedded input.\n",
    "        S: int, the length of source input sentence.\n",
    "        L: int, the number of the classes used to represent fertility.\n",
    "        \n",
    "    Shape:\n",
    "        input: LongTensor, [N, S]\n",
    "        output: FloatTensor, [T, N, vocab_tgt], T=S*L    \n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_src, vocab_tgt, S, d_embed=512, L=50, nhead=8, num_encoder_layers=6,\n",
    "                 num_decoder_layers=6, dim_feedforward=2048, dropout=0.1, activation=\"relu\"):\n",
    "        super(NAT, self).__init__()\n",
    "        \n",
    "        self.d_embed = d_embed\n",
    "        self.S = S\n",
    "        self.L = L\n",
    "        self.T = S*L\n",
    "        max_seq_len = S*L\n",
    "        \n",
    "        self.embedding_input = nn.Embedding(vocab_src, d_embed)\n",
    "        self.position_encoder_en = PositionalEncoding(d_embed, S)\n",
    "        self.position_encoder_de = PositionalEncoding(d_embed, S*L)\n",
    "        self.encoder = EncoderStack(d_embed, nhead, num_encoder_layers, dim_feedforward, dropout, activation)\n",
    "        self.fertility_predictor = FertilityPredictor(d_embed, L)\n",
    "        self.decoder = DecoderStack(d_embed, nhead, max_seq_len, num_decoder_layers, dim_feedforward, dropout, activation)\n",
    "        self.translation_predictor = TranslationPredictor(d_embed, vocab_tgt)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        input_e = self.embedding_input(input.transpose(0,1)) # input_e: [S, N, E]\n",
    "        input_pe = self.position_encoder_en(input_e) # input_pe: [S, N, E]\n",
    "        encoder_output = self.encoder(input_e) # encoder_output: [S, N, E] ---------------\n",
    "        fertility_list = self.fertility_predictor(encoder_output) # fertility_list: [S, N]\n",
    "        copied_embedding = self.copy_fertility(input_e, fertility_list, self.L) # copied_embedding: [T, N, E]\n",
    "        copied_embedding_pe = self.position_encoder_de(copied_embedding) # copied_embedding_pe: [T, N, E]\n",
    "        memory = encoder_output\n",
    "        decoder_output = self.decoder(copied_embedding_pe, memory) # decoder_output: [T, N, E]\n",
    "        output = self.translation_predictor(decoder_output) # output: [T, N, E]\n",
    "        \n",
    "        return output\n",
    "        \n",
    "        \n",
    "    def copy_fertility(self, input_e, fertility_list, L):\n",
    "        \"\"\"Copy the input embedding as the number at corresponding index.\n",
    "        \n",
    "        Args:\n",
    "            input_e: [S, N, E].\n",
    "            fertility_list: [S, N].\n",
    "            L: int, the number of the classes used to represent fertility.\n",
    "        \n",
    "        Output:\n",
    "            copied_embedding: [T, N, E]\n",
    "        \"\"\"\n",
    "        # copy as fertitlity list\n",
    "        [S, N, E] = input_e.shape\n",
    "        copied_embedding = torch.zeros(N, S*L, E) # copied_embedding: [N, S*L, E]\n",
    "        input_e_permute = input_e.permute(1,0,2) # input_e_permute: [N, S, E]\n",
    "        fertility_list_permute = fertility_list.transpose(0,1) # fertility_list_permuet: [N, S]\n",
    "        \n",
    "        # use fertility list and embedded input to get decoder's input.\n",
    "        for i, fertility_batch in enumerate(fertility_list_permute):\n",
    "            pos = 0\n",
    "            for j, fertility_j in enumerate(fertility_batch):\n",
    "                if fertility_j == 0:\n",
    "                    continue\n",
    "                copied_embedding[i,pos:pos+int(fertility_j),:] = input_e_permute[i,j,:].repeat(1,int(fertility_j),1)\n",
    "                pos += int(fertility_j)\n",
    "        copied_embedding = copied_embedding.transpose(0,1)\n",
    "        \n",
    "        return copied_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randint(0, 1000, (16, 20)).long() # input: [N, S]\n",
    "model = NAT(vocab_src=1000, vocab_tgt=500, S=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 20]) torch.Size([16, 1000, 512]) torch.Size([16, 20, 512])\n"
     ]
    }
   ],
   "source": [
    "output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 16, 500])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
